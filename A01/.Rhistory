age.kurtosis
# Subject Age, Model Fit and Vehicle Year:
mydata$subject.age.log <- log(mydata$subject.age)
# 1a)
# Generate a table that shows the number AND
# percentage of stops for each category
### Ask about the best way to sort and send "other" to the end
# Categories: subject.race or vehicle.make
# sorting by cities
cities = mydata$city
mydata <- read.csv("stat231f25dataset.csv")
# Introductory Material // Loading Dataset
mydata <- read.csv("stat231f25dataset.csv")
setwd("C:/Users/wujas/Desktop/LearningR")
age.kurtosis
# Subject Age, Model Fit and Vehicle Year:
mydata$subject.age.log <- log(mydata$subject.age)
# Introductory Material // Loading Dataset
mydata <- read.csv("stat231f25dataset.csv")
# Introductory Material // Loading Dataset
mydata <- read.csv("stat231f25dataset.csv")
# Subject Age, Model Fit and Vehicle Year:
mydata$subject.age.log <- log(mydata$subject.age)
setwd("C:/Users/wujas/Desktop/LearningR/A01")
# Subject Age, Model Fit and Vehicle Year:
mydata$subject.age.log <- log(mydata$subject.age)
mydata <- read.csv("stat231f25dataset.csv")
# Introductory Material // Loading Dataset
mydata <- read.csv("stat231f25dataset.csv")
dim(mydata)
colnames(mydata)
mydata[1:5, 13:14]
mydata$vehicle.make[1:5]
# Checking NA values
sum(is.na(mydata))
# 1a)
# Generate a table that shows the number AND
# percentage of stops for each category
### Ask about the best way to sort and send "other" to the end
# Categories: subject.race or vehicle.make
# sorting by cities
cities = mydata$city
# Saving tables for wanted data
vehicle_make <- mydata$vehicle.make
subject_race <- mydata$subject.race
# Taking into account the city they're recorded in
vehicle_make_by_city <- table(vehicle_make, cities)
# Number of the vehicles per city by stop
vehicle_make_by_city
# Find the percent
prop.table(vehicle_make_by_city, margin = 2) * 100
# Applying the same to race:
subject_race_by_city <- table(subject_race, cities)
subject_race_by_city
prop.table(subject_race_by_city, margin=2) * 100
# We want to find the number and the percent for each
# We'll use the table() function to create the frequency
# tables for each of the columns
table_vehicle <- table(vehicle_make)
table_vehicle
table_race <- table(subject_race)
table_race
# To find the percent, we'll take the number of
# frequencies and divide by the total:
# Given the dataset, this should be same total for both
total <- sum(table_vehicle)
percent_vehicle <- (100 * (table_vehicle) / total)
percent_vehicle
percent_race <- (100* (table_race) / total)
percent_race
#1b)
# Generate a barplot for each city for the number
# of total stops within each category
# First, let's separate our data for specific cities
cities <- mydata$city
# Looking for a table to create a grouped barplot
vehicle_stops <- table(cities, vehicle_make)
race_stops <- table(cities, subject_race)
# Viewing our data
vehicle_stops
race_stops
# Looks good, moving on to creating a grouped barchart
# Choosing 420 as an arbitrary ylimit.
vehicle_bar_plot <- barplot(vehicle_stops, beside=T, xlab="Vehicle Makes",
ylab = "Stop Frequencies", las = 1,
main = "stops from vehicle.make and cities",
col = c("forestgreen", "dodgerblue3"))
legend("topright", legend=c("NO", "SA"), fill = c("forestgreen", "dodgerblue3"),
density=50, angle=c(45, 135))
# race_bar_plot <- barplot(race_stops, beside=T, col=c("forestgreen", "dodgerblue3"))
# 1c)
# is the distribution of your chosen variate similar
# or different for the cities?
# for the vehicle makes, it looks more even, numbers vary my a maximum of 6%
# per category. Do to the symmetry of the data, one could reasonable
# extrapolate that the make of vehicle doesn't have a substantial impact
# on whether or not its stopped
# race is another story...
# Subject Age, Model Fit and Vehicle Year:
mydata$subject.age.log <- log(mydata$subject.age)
# Creating a subset of SanAntonio:
SanAntonio <- subset(mydata, city=="sa")
SanAntonio
# 2a)
# We want to calculate the sample mean, sample median and sample std
# sample skewness and sample kurtosis for each of subject.age.log and
# subject.age.log for San Antonio. Display your results in a table:
# Mean from the mean() function
age.mean <- mean(SanAntonio$subject.age)
age.log.mean <- mean(SanAntonio$subject.age.log)
# Median from the summary
summary(SanAntonio$subject.age)
summary(SanAntonio$subject.age.log)
# sample standard deviation
age.sd <- sd(SanAntonio$subject.age)
age.log.sd <- sd(SanAntonio$subject.age.log)
# Defining Skewness and Kurtosis Functions:
# Skewness:
skewness <- function(x) {
(sum((x - mean(x))^3)/length(x))/(sum((x - mean(x))^2)/length(x))^(3/2)
}
#Kurtosis:
kurtosis <- function(x) {
(sum((x - mean(x))^4)/length(x))/(sum((x - mean(x))^2)/length(x))^2
}
# Saving Variables
age.skewness <- skewness(SanAntonio$subject.age)
age.log.skewness <- skewness(SanAntonio$subject.age.log)
# age.kurtosis
# age.log.kurtosis
age.kurtosis <- kurtosis(SanAntonio$subject.age)
age.log.kurtosis <- kurtosis(SanAntonio$subject.age.log)
# age.kurtosis
# age.log.kurtosis
# At this point, can I stop with the variables, or is there a better way
# to present this information in a table? Not sure if we've been taught how to
# take variables and present them in a dataframe/table
# 2b) Generate a relative frequency histogram with a suitable
# superimposed Gaussain Probability Density Function curve for each of
# subject.age and subject.age.log for San Antonio.
# First, we need to download the library to run a relative frequency histogram
# and gain access to truehist. I'll also use the command to allow 2 images in my
# plotting window:
library(MASS)
par(mfrow = c(1,2))
truehist(SanAntonio$subject.age, xlab = "Age of Subjects",
ylab = "Relative Frequency", main = "Relative Frequency Histogram of Subject's Ages",
col = "dodgerblue3")
truehist(SanAntonio$subject.age.log, xlab = "log Age of Subjects",
ylab = "Relative Frequency", main = "Relative Frequency Histogram of the Log of Subject's Ages",
col = "dodgerblue3")
# Adding a Gaussain Probability Density Function
# Copying and pasting the histograms above and adding:
truehist(SanAntonio$subject.age, xlab = "Age of Subjects",
ylab = "Relative Frequency", main = "Relative Frequency Histogram of Subject's Ages",
col = "dodgerblue3")
curve(dnorm(x, age.mean, age.sd), col="red", add=TRUE, lwd=1.5)
truehist(SanAntonio$subject.age.log, xlab = "log Age of Subjects",
ylab = "Relative Frequency", main = "Relative Frequency Histogram of the Log of Subject's Ages",
col = "dodgerblue3")
curve(dnorm(x, age.log.mean, age.log.sd), col='red', add=TRUE, lwd=1.5)
# I'd like to note here that this choice of bins, though default, looks pretty
# good for the shape of the graph. Though it may help to trial an error
# some other bin sizes and see if something else is better.
# 2c)
# plot an e.c.d.f for this dataset:
plot(ecdf(SanAntonio$subject.age), xlab = "Subject's Ages",
main="e.c.d.f of Subject Ages",
las=1, lwd=2, pch=NA)
curve(pnorm(x, age.mean, age.sd), col="red", add=TRUE, lwd=1.5, lty=2)
plot(ecdf(SanAntonio$subject.age.log), xlab="Log of Subject's Ages",
main="e.c.d.f of log of Subject Ages",
las=1, lwd=2, pch=NA)
curve(pnorm(x, age.log.mean, age.log.sd), col="red", add=TRUE, lwd=1.5, lty=2)
# 2d)
# How well does your data fit a Gaussian Model?
# from the original dataset, we can find the mean, median, skewness and kurtosis
age.kurtosis
age.skewness
age.log.kurtosis
age.log.skewness
plot(SanAntonio$subject.age, SanAntonio$vehicle.year, xlab="age", ylab="vehicle age")
cor(SanAntonio$subject.age, SanAntonio$vehicle.year)
SanAntonio$vehicle.make
SanAntonio$vehicle.make["ford"]
SanAntonio$vehicle.make=="ford"
sum(SanAntonio$vehicle.make=="ford")
size(SanAntonio)
size(SanAntonio$vehicle.make)
sum(SanAntonio$vehicle.make)
sum(SanAntonio$vehicle.make)
sum(table(SanAntonio$vehicle.make))
num=sum(SanAntonio$vehicle.make=="ford")
denom = sum(table(SanAntonio$vehicle.make))
percent = 100*num/denom
percent
summary(SanAntonio$vehicle.year)
2019 - 1986
NewOrleans <- subset(mydata, city=="no")
mode(SanAntonio$vehicle.colour)
#3a)
# favourite animal (group) - I think snow leopards are pre cool
# favourite animal (specific) - my dog Izzy. She's a poodle.
#3b)
num=sum(SanAntonio$vehicle.make=="ford")
denom = sum(table(SanAntonio$vehicle.make))
percent = 100*num/denom
percent
# around 15.3%
#3c)
summary(SanAntonio$vehicle.year)
# the range is from the max = 2019, subtracted by the min = 1986
2019 - 1986
# 33
#3d)
NewOrleans <- subset(mydata, city=="no")
mode(SanAntonio$vehicle.colour)
mode(NewOrleans$vehicle.colour)
SanAntonio$vehicle.colour
# 1a)
# Generate a table that shows the number AND
# percentage of stops for each category
### Ask about the best way to sort and send "other" to the end
# Categories: subject.race or vehicle.make
# sorting by cities
cities = mydata$city
# Saving tables for wanted data
vehicle_make <- mydata$vehicle.make
subject_race <- mydata$subject.race
# Taking into account the city they're recorded in
vehicle_make_by_city <- table(vehicle_make, cities)
# Number of the vehicles per city by stop
vehicle_make_by_city
# Find the percent
prop.table(vehicle_make_by_city, margin = 2) * 100
# Applying the same to race:
subject_race_by_city <- table(subject_race, cities)
subject_race_by_city
prop.table(subject_race_by_city, margin=2) * 100
# We want to find the number and the percent for each
# We'll use the table() function to create the frequency
# tables for each of the columns
table_vehicle <- table(vehicle_make)
table_vehicle
table_race <- table(subject_race)
table_race
# To find the percent, we'll take the number of
# frequencies and divide by the total:
# Given the dataset, this should be same total for both
total <- sum(table_vehicle)
percent_vehicle <- (100 * (table_vehicle) / total)
percent_vehicle
percent_race <- (100* (table_race) / total)
percent_race
#1b)
# Generate a barplot for each city for the number
# of total stops within each category
# First, let's separate our data for specific cities
cities <- mydata$city
# Looking for a table to create a grouped barplot
vehicle_stops <- table(cities, vehicle_make)
race_stops <- table(cities, subject_race)
# Viewing our data
vehicle_stops
race_stops
# Looks good, moving on to creating a grouped barchart
# Choosing 420 as an arbitrary ylimit.
vehicle_bar_plot <- barplot(vehicle_stops, beside=T, xlab="Vehicle Makes",
ylab = "Stop Frequencies", las = 1,
main = "stops from vehicle.make and cities",
col = c("forestgreen", "dodgerblue3"))
legend("topright", legend=c("NO", "SA"), fill = c("forestgreen", "dodgerblue3"),
density=50, angle=c(45, 135))
# race_bar_plot <- barplot(race_stops, beside=T, col=c("forestgreen", "dodgerblue3"))
# 1c)
# is the distribution of your chosen variate similar
# or different for the cities?
# for the vehicle makes, it looks more even, numbers vary my a maximum of 6%
# per category. Do to the symmetry of the data, one could reasonable
# extrapolate that the make of vehicle doesn't have a substantial impact
# on whether or not its stopped
# race is another story...
#3a)
# favourite animal (group) - I think snow leopards are pre cool
# favourite animal (specific) - my dog Izzy. She's a poodle.
#3b)
num=sum(SanAntonio$vehicle.make=="ford")
denom = sum(table(SanAntonio$vehicle.make))
percent = 100*num/denom
percent
# around 15.3%
#3c)
summary(SanAntonio$vehicle.year)
# the range is from the max = 2019, subtracted by the min = 1986
2019 - 1986
# 33
#3d)
NewOrleans <- subset(mydata, city=="no")
table(SanAntonio$vehicle.colour)
table(NewOrleans$vehicle.colour)
